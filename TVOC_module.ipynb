{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import seaborn as sns\n",
    "import re\n",
    "from decimal import Decimal\n",
    "from docx import Document \n",
    "from docx.oxml.ns import qn\n",
    "from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
    "from docx.enum.table import WD_ALIGN_VERTICAL\n",
    "from docx.shared import Cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concentration_process(path_):\n",
    "    data = pd.read_csv(\"data/\"+path_,sep=r'\\s+',names=[str(i) for i in range(2500)])\n",
    "    num = int(re.findall(r'\\d+', path_[20:-4])[3])\n",
    "    data=data.transpose()\n",
    "    concentration_origin=data.iloc[1024+65:1024+65+num,:]\n",
    "    data=data[65:65+num]\n",
    "    data=data.dropna(how=\"all\",axis=0)\n",
    "    # data = data[data.sum(axis=1) != 0][1:]\n",
    "    return data,concentration_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filepaths(dir):\n",
    "    filepaths = []\n",
    "    for filename in os.listdir(dir):\n",
    "        filepath = os.path.join(dir, filename)\n",
    "        if os.path.isfile(filepath):\n",
    "            filepaths.append(filepath)\n",
    "    return filepaths\n",
    "\n",
    "def gain_batch_name(filepaths):\n",
    "    batch_name = filepaths[0][15:]\n",
    "    pattern = r'\\d+'\n",
    "    numbers = re.findall(pattern, batch_name)\n",
    "    batch_name = filepaths[0][15:]\n",
    "    batch_name_1=\"\"\n",
    "    batch_name_1+=batch_name[:batch_name.find(numbers[0])+numbers[0].__len__()]\n",
    "    batch_name=batch_name[batch_name.find(numbers[0])+numbers[0].__len__():]\n",
    "    batch_name_1+=batch_name[:batch_name.find(numbers[1])+numbers[1].__len__()]\n",
    "    batch_name_2=batch_name_1\n",
    "    batch_name=batch_name[batch_name.find(numbers[1])+numbers[1].__len__():]\n",
    "    batch_name=batch_name[batch_name.find(numbers[2])+numbers[2].__len__():]\n",
    "    total_num = sum([int(re.findall(pattern, i[15:])[3]) for i in filepaths])\n",
    "    batch_name_1+=\"_\"+str(total_num)+batch_name[batch_name.find(numbers[3])+numbers[3].__len__():-4]\n",
    "    batch_name=batch_name_1\n",
    "    batch=batch_name[:2]\n",
    "    return batch,batch_name,batch_name_2,total_num\n",
    "\n",
    "def import_scale():\n",
    "    scale = pd.read_csv(\"scale_file.csv\").T\n",
    "    scale.index=[\"response_resistance_x\",\"response_size_x\",\"discrimination_x\",\"response_stability_x\",\"restoration_x\",\"baseline_deviation_x\",\"high_discrimination_x\"\n",
    "                    ]\n",
    "    return scale\n",
    "def concat_data(filepaths):\n",
    "\n",
    "    if pd.read_csv(\"data/\"+filepaths[0],sep=r'\\s+',names=[str(i) for i in range(2500)]).columns.__len__()==7:\n",
    "        data_total = pd.DataFrame(columns=[i for i in range(6)])\n",
    "        concentration_origin_total = pd.DataFrame(columns=[i for i in range(6)])\n",
    "        for j,i in enumerate(filepaths):\n",
    "            data,concentration_origin = concentration_process(i)\n",
    "            data[\"no\"] = data.index.values.astype(int)\n",
    "            data[\"batch\"]=filepaths[j][15:-4]\n",
    "            data_total= pd.concat([data_total,data])\n",
    "            concentration_origin_total=pd.concat([concentration_origin_total,concentration_origin])\n",
    "        \n",
    "        return data_total,(concentration_origin_total[2])\n",
    "    else:\n",
    "\n",
    "        data_total = pd.DataFrame(columns=[i for i in range(7)])\n",
    "        concentration_origin_total = pd.DataFrame(columns=[i for i in range(7)])\n",
    "        for j,i in enumerate(filepaths):\n",
    "            data,concentration_origin = concentration_process(i)\n",
    "            data[\"no\"] = data.index.values.astype(int)\n",
    "            data[\"batch\"]=filepaths[j][15:-4]\n",
    "            data_total= pd.concat([data_total,data])\n",
    "            concentration_origin_total=pd.concat([concentration_origin_total,concentration_origin])\n",
    "\n",
    "        return data_total,concentration_origin_total[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(batch_name,scale,data_total,total_num,filepaths,concentration):\n",
    "    \n",
    "    response_resistance_x=list(scale[scale.index==\"response_resistance_x\"].T[\"response_resistance_x\"])\n",
    "    response_size_x=list(scale[scale.index==\"response_size_x\"].T[\"response_size_x\"])\n",
    "    discrimination_x=list(scale[scale.index==\"discrimination_x\"].T[\"discrimination_x\"])\n",
    "    response_stability_x=list(scale[scale.index==\"response_stability_x\"].T[\"response_stability_x\"])\n",
    "    restoration_x=list(scale[scale.index==\"restoration_x\"].T[\"restoration_x\"])\n",
    "    baseline_deviation_x=list(scale[scale.index==\"baseline_deviation_x\"].T[\"baseline_deviation_x\"])\n",
    "    high_discrimination_x=list(scale[scale.index==\"high_discrimination_x\"].T[\"high_discrimination_x\"])\n",
    "\n",
    "    response_resistance_x=[x for x in response_resistance_x if not math.isnan(x)]\n",
    "    response_size_x=[x for x in response_size_x if not math.isnan(x)]\n",
    "    discrimination_x=[x for x in discrimination_x if not math.isnan(x)]\n",
    "    response_stability_x=[x for x in response_stability_x if not math.isnan(x)]\n",
    "    restoration_x=[x for x in restoration_x if not math.isnan(x)]\n",
    "    baseline_deviation_x=[x for x in baseline_deviation_x if not math.isnan(x)]\n",
    "    high_discrimination_x=[x for x in high_discrimination_x if not math.isnan(x)]\n",
    "\n",
    "    if data_total.columns.__len__()==10:\n",
    "        response_size = data_total[0]/data_total[4]\n",
    "        discrimination = data_total[4]/data_total[3]\n",
    "        response_stability=data_total[5]/data_total[4]\n",
    "        restoration=data_total[6]/data_total[0]\n",
    "        baseline_deviation=(data_total[0]-data_total[7])/data_total[0]\n",
    "        high_discrimination=data_total[2]/data_total[1]\n",
    "        \n",
    "    if data_total.columns.__len__()==9:\n",
    "        response_resistance = data_total[2]\n",
    "        response_size = data_total[0]/data_total[2]\n",
    "        discrimination = data_total[2]/data_total[1]\n",
    "        response_stability = data_total[3]/data_total[2]\n",
    "        restoration = data_total[4]/data_total[0]\n",
    "        baseline_deviation=(data_total[0]-data_total[6])/data_total[0]\n",
    "\n",
    "    y_1=[0]+list(pd.cut(response_resistance,bins=response_resistance_x).value_counts(sort=False,normalize=True)[:11].values)\n",
    "    y_2=[0]+list(pd.cut(response_size,bins=response_size_x).value_counts(sort=False,normalize=True)[:16].values)\n",
    "    y_3=[0]+list(pd.cut(discrimination,bins=discrimination_x).value_counts(sort=False,normalize=True)[5:25].values)\n",
    "    y_4=[0]+list(pd.cut(response_stability,bins=response_stability_x).value_counts(sort=False,normalize=True)[10:30].values)\n",
    "    y_5=[0]+list(pd.cut(restoration,bins=restoration_x).value_counts(sort=False,normalize=True)[17:-1].values)\n",
    "    y_6=[0]+list(pd.cut(baseline_deviation,bins=baseline_deviation_x).value_counts(sort=False,normalize=True)[15:-1].values)\n",
    "\n",
    "    x_1=response_resistance_x[:12]\n",
    "    x_2=response_size_x[:17]\n",
    "    x_3=discrimination_x[5:26]\n",
    "    x_4=response_stability_x[10:31]\n",
    "    x_5=restoration_x[17:-1]\n",
    "    x_6=baseline_deviation_x[15:-1]\n",
    "    if data_total.columns.__len__()==8:\n",
    "        x_7=high_discrimination_x[5:27]\n",
    "        y_7=[0]+list(pd.cut(high_discrimination,bins=high_discrimination_x).value_counts(sort=False,normalize=True)[5:26].values)\n",
    "\n",
    "    plt.rcParams['font.sans-serif'] = ['Microsoft YaHei'] \n",
    "    plt.rcParams[\"font.size\"] =35\n",
    "    plt.figure(figsize=(20,12))\n",
    "    plt.title(\"响应电阻(R$^{1}$$_{50}$)\",pad=40)\n",
    "    plt.xlabel(\"响应电阻值（KΩ）\",labelpad=20)\n",
    "    plt.ylabel(\"比例\")\n",
    "    plt.grid( axis='y', linewidth=0.3)\n",
    "    plt.ylim(0,0.8)\n",
    "    plt.plot(x_1, y_1 ,marker='D', markersize=12, linewidth=4.5)\n",
    "    plt.savefig('响应电阻.png')\n",
    "    plt.close()\n",
    "    print(\"409600:\",pd.cut(response_resistance,bins=response_resistance_x).value_counts(sort=False).values[-1])\n",
    "\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    plt.title(\"响应大小(R$^{1}$$_{0}$/R$^{1}$$_{50}$)\",pad=40)\n",
    "    plt.xlabel(\"响应大小\",labelpad=20)\n",
    "    plt.ylabel(\"比例\")\n",
    "    plt.grid( axis='y', linewidth=0.3)\n",
    "    plt.ylim(0,0.6)\n",
    "    plt.plot(x_2, y_2, marker='D', markersize=12, linewidth=4.5)\n",
    "    plt.savefig('响应大小.png')\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    plt.title(\"区分度(R$^{1}$$_{50}$/R$_{80}$)\",pad=40)\n",
    "    plt.xlabel(\"区分度\",labelpad=20)\n",
    "    plt.ylabel(\"比例\")\n",
    "    plt.grid( axis='y', linewidth=0.3)\n",
    "    plt.ylim(0,0.8)\n",
    "    plt.plot(x_3, y_3, marker='D', markersize=12, linewidth=4.5)\n",
    "    plt.savefig('区分度.png')\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    plt.title(\"响应稳定性(R$^{2}$$_{50}$/R$^{1}$$_{50}$)\",pad=40)\n",
    "    plt.xlabel(\"响应稳定性\",labelpad=20)\n",
    "    plt.ylabel(\"比例\")\n",
    "    plt.grid( axis='y', linewidth=0.3)\n",
    "    plt.ylim(0,0.8)\n",
    "    plt.plot(x_4, y_4, marker='D', markersize=12, linewidth=4.5)\n",
    "    plt.savefig('响应稳定性.png')\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    plt.title(\"恢复程度(R$_{53}$/R$^{1}$$_{0}$)\",pad=40)\n",
    "    plt.xlabel(\"恢复程度\",labelpad=20)\n",
    "    plt.ylabel(\"比例\")\n",
    "    plt.grid( axis='y', linewidth=0.3)\n",
    "    plt.ylim(0,0.8)\n",
    "    plt.plot(x_5, y_5, marker='D', markersize=12, linewidth=4.5)\n",
    "    plt.savefig('恢复程度.png')\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    plt.title(\"基线偏差[(R$^{1}$$_{0}$-R$^{2}$$_{0}$)/R$^{1}$$_{0}$]\",pad=40)\n",
    "    plt.xlabel(\"基线偏差\",labelpad=20)\n",
    "    plt.ylabel(\"比例\")\n",
    "    plt.grid( axis='y', linewidth=0.3)\n",
    "    plt.ylim(0,0.8)\n",
    "    plt.plot(x_6, y_6, marker='D', markersize=12, linewidth=4.5)\n",
    "    plt.savefig('基线偏差.png')\n",
    "    plt.close()\n",
    "\n",
    "    if data_total.columns.__len__()==8:\n",
    "        plt.title(\"大浓度区分度值(R$_{200}$/R$_{100}$)\",pad=40)\n",
    "        plt.xlabel(\"大浓度区分度值\",labelpad=20)\n",
    "        plt.ylabel(\"比例\")\n",
    "        plt.grid( axis='y', linewidth=0.3)\n",
    "        plt.plot(x_7, y_7, marker='D', markersize=12, linewidth=4.5)\n",
    "        plt.savefig('大浓度区分度值.png')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    no_=data_total.index.values.astype(int)\n",
    "    if data_total.columns.__len__()==9:\n",
    "        data_processed = pd.concat(\n",
    "            [pd.Series(no_,index=response_resistance.index),\n",
    "            response_resistance,response_size,discrimination,response_stability,restoration,baseline_deviation\n",
    "            ,concentration,data_total[\"batch\"]],axis=1)\n",
    "        columns=[\"序号\",\"响应电阻\",\n",
    "        \"响应大小\",\n",
    "        \"区分度\",\n",
    "        \"响应稳定性\",\n",
    "        \"恢复程度\",\n",
    "        \"基线偏差\",\n",
    "        \"响应浓度值\",\n",
    "        \"部分\"\n",
    "        ]\n",
    "    if data_total.columns.__len__()==10:\n",
    "        data_processed = pd.concat(\n",
    "            [pd.Series(no_,index=response_resistance.index),\n",
    "            response_resistance,response_size,discrimination,response_stability,restoration,baseline_deviation,high_discrimination\n",
    "            ,concentration,data_total[\"batch\"]],axis=1)\n",
    "        columns=[\"序号\",\"响应电阻\",\n",
    "        \"响应大小\",\n",
    "        \"区分度\",\n",
    "        \"响应稳定性\",\n",
    "        \"恢复程度\",\n",
    "        \"基线偏差\",\n",
    "        \"大浓度区分度\",\n",
    "        \"响应浓度值\",\n",
    "        \"部分\"\n",
    "        ]\n",
    "    data_processed.columns=columns\n",
    "    step_1=pd.merge(\n",
    "        data_processed[data_processed[\"响应电阻\"]>=3] , data_processed[data_processed[\"响应电阻\"]<=30],how=\"inner\"\n",
    "        )\n",
    "\n",
    "    step_2=pd.merge(\n",
    "        step_1[step_1[\"响应大小\"]>=2] , step_1[step_1[\"响应大小\"]<=15],how=\"inner\"\n",
    "        )\n",
    "\n",
    "\n",
    "    step_3=pd.merge(\n",
    "        step_2[step_2[\"区分度\"]>=1.1] , step_2[step_2[\"区分度\"]<=1.5],how=\"inner\"\n",
    "        )\n",
    "\n",
    "\n",
    "    step_4=pd.merge(\n",
    "        step_3[step_3[\"响应稳定性\"]>=0.95] , step_3[step_3[\"响应稳定性\"]<=1.05],how=\"inner\"\n",
    "        )\n",
    "\n",
    "\n",
    "    step_5=step_4[step_4[\"恢复程度\"]>0.75]\n",
    "\n",
    "    step_6=pd.merge(\n",
    "        step_5[step_5[\"基线偏差\"]>=-0.2] , step_5[step_5[\"基线偏差\"]<=0.1],how=\"inner\"\n",
    "        )\n",
    "    con_filter_1=pd.merge(\n",
    "        step_6[step_6[\"响应浓度值\"]>=45] , step_6[step_6[\"响应浓度值\"]<=55],how=\"inner\"\n",
    "        )\n",
    "\n",
    "    con_filter_2_1=pd.merge(\n",
    "        step_6[step_6[\"响应浓度值\"]>=40] , step_6[step_6[\"响应浓度值\"]<45],how=\"inner\"\n",
    "        )\n",
    "\n",
    "    con_filter_2_2=pd.merge(\n",
    "        step_6[step_6[\"响应浓度值\"]>55] , step_6[step_6[\"响应浓度值\"]<=60],how=\"inner\"\n",
    "        )\n",
    "\n",
    "    con_filter_2=pd.merge(con_filter_2_1,con_filter_2_2)\n",
    "    \n",
    "    if data_total.columns.__len__()==10:\n",
    "        step_7=step_6[step_6[\"大浓度区分度\"]>1.3]\n",
    "\n",
    "\n",
    "        con_filter_1=pd.merge(\n",
    "            step_6[step_6[\"响应浓度值\"]>=45] , step_6[step_6[\"响应浓度值\"]<=55],how=\"inner\"\n",
    "            )\n",
    "\n",
    "        con_filter_2_1=pd.merge(\n",
    "            step_6[step_6[\"响应浓度值\"]>=40] , step_6[step_6[\"响应浓度值\"]<45],how=\"inner\"\n",
    "            )\n",
    "\n",
    "        con_filter_2_2=pd.merge(\n",
    "            step_6[step_6[\"响应浓度值\"]>55] , step_6[step_6[\"响应浓度值\"]<=60],how=\"inner\"\n",
    "            )\n",
    "\n",
    "        con_filter_2=pd.merge(con_filter_2_1,con_filter_2_2)\n",
    "\n",
    "    step_6_=step_6.copy()\n",
    "    step_6_.index=step_6[\"序号\"]\n",
    "    step_6_.index.name=''\n",
    "    merged = pd.concat([data_processed,step_6_])\n",
    "    merged.drop_duplicates(keep=False,inplace=True)\n",
    "\n",
    "    if data_total.columns.__len__()==10:\n",
    "        step_7_=step_7.copy()\n",
    "        step_7_.index=step_7[\"序号\"]\n",
    "        step_7_.index.name=''\n",
    "        merged = pd.concat([data_processed,step_7_])\n",
    "        merged.drop_duplicates(keep=False,inplace=True)\n",
    "\n",
    "    defective_products_1 = []\n",
    "    defective_products_1.append(pd.concat(\n",
    "        [merged[merged[\"响应电阻\"]<3] , merged[merged[\"响应电阻\"]>30]]\n",
    "        ).__len__()/merged.__len__())\n",
    "    defective_products_1.append(pd.concat(\n",
    "        [merged[merged[\"响应大小\"]<2] , merged[merged[\"响应大小\"]>15]]\n",
    "        ).__len__()/merged.__len__())\n",
    "    defective_products_1.append(pd.concat(\n",
    "        [merged[merged[\"区分度\"]<1.1] , merged[merged[\"区分度\"]>1.5]]\n",
    "        ).__len__()/merged.__len__())\n",
    "    defective_products_1.append(pd.concat(\n",
    "        [merged[merged[\"响应稳定性\"]<0.95] , merged[merged[\"响应稳定性\"]>1.05]]\n",
    "        ).__len__()/merged.__len__())\n",
    "    defective_products_1.append(merged[merged[\"恢复程度\"]<=0.75].__len__()/merged.__len__())\n",
    "    defective_products_1.append(pd.concat(\n",
    "        [merged[merged[\"基线偏差\"]<-0.2] , merged[merged[\"基线偏差\"]>0.1]]\n",
    "        ).__len__()/merged.__len__())\n",
    "    if data_total.columns.__len__()==10:\n",
    "        defective_products_1.append(merged[merged[\"大浓度区分度\"]<=1.3].__len__()/merged.__len__())\n",
    "\n",
    "    defective_products_2 = []\n",
    "    defective_products_2.append(pd.concat(\n",
    "        [merged[merged[\"响应电阻\"]<3] , merged[merged[\"响应电阻\"]>30]]\n",
    "        ).__len__())\n",
    "    defective_products_2.append(pd.concat(\n",
    "        [merged[merged[\"响应大小\"]<2] , merged[merged[\"响应大小\"]>15]]\n",
    "        ).__len__())\n",
    "    defective_products_2.append(pd.concat(\n",
    "        [merged[merged[\"区分度\"]<1.1] , merged[merged[\"区分度\"]>1.5]]\n",
    "        ).__len__())\n",
    "    defective_products_2.append(pd.concat(\n",
    "        [merged[merged[\"响应稳定性\"]<0.95] , merged[merged[\"响应稳定性\"]>1.05]]\n",
    "        ).__len__())\n",
    "    defective_products_2.append(merged[merged[\"恢复程度\"]<=0.75].__len__())\n",
    "    defective_products_2.append(pd.concat(\n",
    "        [merged[merged[\"基线偏差\"]<-0.2] , merged[merged[\"基线偏差\"]>0.1]]\n",
    "        ).__len__())\n",
    "    if data_total.columns.__len__()==10:\n",
    "        defective_products_2.append(merged[merged[\"大浓度区分度\"]<=1.3].__len__())\n",
    "    defective_products_x=[\"不符合响应电阻\",\"不符合响应大小\",\"不符合区分度\",\"不符合响应稳定性\",\"不符合恢复程度\",\"不符基线偏差\"]\n",
    "    if data_total.columns.__len__()==10:\n",
    "        defective_products_x=[\"不符合响应电阻\",\"不符合响应大小\",\"不符合区分度\",\"不符合响应稳定性\",\"不符合恢复程度\",\"不符基线偏差\",\"不符合大浓度区分度\"]\n",
    "    \n",
    "    # sns.set()\n",
    "    plt.rcParams[\"font.size\"] =27\n",
    "    plt.rcParams['font.sans-serif'] = ['Microsoft YaHei'] \n",
    "    # plt.rcParams['font.sans-serif'] = ['SimSun']\n",
    "    fig=plt.figure(figsize=(22, 12),dpi=120)\n",
    "    axis_1 = fig.add_axes((0.1, 0.1, 0.8, 0.8))\n",
    "    # plt.yticks([i for i in np.linspace(0,1,num=6)],[str(round(i,1)*100)[:3]+\"%\"for i in np.linspace(0, 1, num=6)])\n",
    "\n",
    "\n",
    "    colors = [\"#5470C6\" for i in range(defective_products_x.__len__())]\n",
    "    colors[:3]=[\"#A60000\" for i in range(3)]\n",
    "    axis_1.bar(defective_products_x,defective_products_2,width=0.5, alpha=0.8,color=colors,label=\"数量\")\n",
    "    axis_1.set_ylabel(\"数量\", size=30) \n",
    "\n",
    "    plt.legend(['数量'],loc='best',framealpha=0.5)\n",
    "    axis_2 = axis_1.twinx()\n",
    "    axis_2.plot(defective_products_x, defective_products_1, color=\"#6AA84F\", marker=\"o\", linewidth=4.5,label=\"比例\")\n",
    "    for i in range(defective_products_1.__len__()):  \n",
    "        plt.text(defective_products_x[i], defective_products_1[i], str(round(Decimal(defective_products_1[i]),4)*100)[:4]+\"%\", ha='center', va= 'bottom',fontweight='bold')\n",
    "    axis_2.set_ylabel(\"比例\", size=30)\n",
    "    axis_2.xaxis.set_tick_params(pad=20) \n",
    "\n",
    "    # plt.ylim(0,896)\n",
    "    plt.grid(True, linewidth=0.3)\n",
    "    plt.title(batch_name+\"不良品统计情况\", size=45,pad=40)\n",
    "    plt.legend(['比例'],loc=1,framealpha=0.5,bbox_to_anchor=(1,0.90))\n",
    "    plt.savefig(\"不良率.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    filtered_no=[]\n",
    "    for j,i in enumerate(con_filter_1[\"序号\"]):\n",
    "            if int(i)%64 == 0:\n",
    "                filtered_no.append(str(int(i)//64-1)+\"+\"+str(64)+\" \"+batch_name)\n",
    "            else:  filtered_no.append(str(int(i)//64)+\"+\"+str(int(i)%64)+\" \"+batch_name)\n",
    "    con_filter_1[\"序号\"]=filtered_no\n",
    "\n",
    "    filtered_no=[]\n",
    "    for j,i in enumerate(con_filter_2[\"序号\"]):\n",
    "            if int(i)%64 == 0:\n",
    "                filtered_no.append(str(int(i)//64-1)+\"+\"+str(64)+\" \"+batch_name)\n",
    "            else:  filtered_no.append(str(int(i)//64)+\"+\"+str(int(i)%64)+\" \"+batch_name)\n",
    "    con_filter_2[\"序号\"]=filtered_no\n",
    "\n",
    "    filtered_no=[]\n",
    "    for j,i in enumerate(step_6[\"序号\"]):\n",
    "            if int(i)%64 == 0:\n",
    "                filtered_no.append(str(int(i)//64-1)+\"+\"+str(64)+\" \"+batch_name)\n",
    "            else:  filtered_no.append(str(int(i)//64)+\"+\"+str(int(i)%64)+\" \"+batch_name)\n",
    "    step_6[\"序号\"]=filtered_no\n",
    "        \n",
    "    booth=[]\n",
    "    step_6.to_excel(\"report/processed_total_\"+batch_name+\".xlsx\")\n",
    "    pd.DataFrame([np.array(con_filter_1[\"序号\"]),booth,np.array(con_filter_2[\"序号\"])]).to_csv(\"report/concentration_filter_\"+batch_name+\".csv\",index=False,header=False)\n",
    "    if data_total.columns.__len__()==10:\n",
    "        step_7.to_excel(\"report/processed_total_\"+batch_name+\".xlsx\")\n",
    "\n",
    "    defective_products = []\n",
    "    defective_products.append(pd.merge(\n",
    "        data_processed[data_processed[\"响应电阻\"]>=3] , data_processed[data_processed[\"响应电阻\"]<=30],how=\"inner\"\n",
    "        ).__len__()/data_processed.__len__())\n",
    "    defective_products.append(pd.merge(\n",
    "        data_processed[data_processed[\"响应大小\"]>=2] , data_processed[data_processed[\"响应大小\"]<=15],how=\"inner\"\n",
    "        ).__len__()/data_processed.__len__())\n",
    "    defective_products.append(pd.merge(\n",
    "        data_processed[data_processed[\"区分度\"]>=1.1] , data_processed[data_processed[\"区分度\"]<=1.5],how=\"inner\"\n",
    "        ).__len__()/data_processed.__len__())\n",
    "    defective_products.append(pd.merge(\n",
    "        data_processed[data_processed[\"响应稳定性\"]>=0.95] , data_processed[data_processed[\"响应稳定性\"]<=1.05],how=\"inner\"\n",
    "        ).__len__()/data_processed.__len__())\n",
    "    defective_products.append(data_processed[data_processed[\"恢复程度\"]>0.75].__len__()/data_processed.__len__())\n",
    "    defective_products.append(pd.merge(\n",
    "        data_processed[data_processed[\"基线偏差\"]>=-0.2] , data_processed[data_processed[\"基线偏差\"]<=0.1],how=\"inner\"\n",
    "        ).__len__()/data_processed.__len__())\n",
    "    if data_total.columns.__len__()==10:\n",
    "        defective_products.append(data_processed[data_processed[\"大浓度区分度\"]>1.3].__len__()/data_processed.__len__())\n",
    "\n",
    "    document =Document()\n",
    "    document.styles['Normal'].font.name='楷体'\n",
    "    document.styles['Normal']._element.rPr.rFonts.set(qn('w:eastAsia'), '楷体')\n",
    "    run=document.add_heading('',level=0).add_run('分析报告')\n",
    "    run.font.name='微软雅黑'\n",
    "    _title = document.styles['Title']\n",
    "    _title.paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "    paragraph = document.add_paragraph('本次测试日期为'+filepaths[0][:5]) \n",
    "    paragraph.paragraph_format.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY\n",
    "    paragraph = document.add_paragraph('本次测试批次为：'+batch_name+'，一共测试'+str(total_num)+\"个器件\")\n",
    "\n",
    "    paragraph = document.add_paragraph('各参数筛选合格率') \n",
    "    paragraph.paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER \n",
    "    table = document.add_table(rows=1, cols=3, style='Table Grid') \n",
    "    table.style.paragraph_format.alignment=WD_ALIGN_PARAGRAPH.CENTER\n",
    "    hdr_cells = table.rows[0].cells\n",
    "    hdr_cells[0].text = '参数名称'\n",
    "    hdr_cells[1].text = '符合参数占比'\n",
    "    hdr_cells[2].text = '不符合参数占比'\n",
    "    table.cell(0,0).width=Cm(5) \n",
    "    table.cell(0,1).width=Cm(10) \n",
    "\n",
    "    if data_total.columns.__len__()==10:\n",
    "        mlst =[\"序号\",\"响应电阻\",\n",
    "        \"响应大小\",\n",
    "        \"区分度\",\n",
    "        \"响应稳定性\",\n",
    "        \"恢复程度\",\n",
    "        \"基线偏差\",\n",
    "        \"大浓度区分度\",\n",
    "        ]\n",
    "    if data_total.columns.__len__()==9:\n",
    "        mlst =[\"响应电阻\",\n",
    "        \"响应大小\",\n",
    "        \"区分度\",\n",
    "        \"响应稳定性\",\n",
    "        \"恢复程度\",\n",
    "        \"基线偏差\",\n",
    "        ]\n",
    "    for i,_row in enumerate(mlst):\n",
    "        row_cells = table.add_row().cells # 添一行表格元素\n",
    "        row_cells[0].text = _row\n",
    "        row_cells[1].text = ' '+str(round(defective_products[i],2)*100)+\"%\"\n",
    "        row_cells[2].text = ' '+str(round(Decimal(1-defective_products[i]),2)*100)[:5]+\"%\"\n",
    "        p = row_cells[1].paragraphs[0]\n",
    "        p.paragraph_format.alignment =WD_ALIGN_PARAGRAPH.JUSTIFY # 单元格文字两端对齐\n",
    "\n",
    "    paragraph = document.add_paragraph(' ')\n",
    "\n",
    "    paragraph = document.add_paragraph('参数筛选区间表') \n",
    "    paragraph.paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER \n",
    "    table = document.add_table(rows=1, cols=2, style='Table Grid') \n",
    "    table.style.paragraph_format.alignment=WD_ALIGN_PARAGRAPH.CENTER\n",
    "    hdr_cells = table.rows[0].cells\n",
    "    hdr_cells[0].text = '参数名称'\n",
    "    hdr_cells[1].text = '区间范围'\n",
    "    table.cell(0,0).width=Cm(5) \n",
    "    table.cell(0,1).width=Cm(10) \n",
    "\n",
    "    if data_total.columns.__len__()==10:\n",
    "        mlst =[\"序号\",\"响应电阻\",\n",
    "        \"响应大小\",\n",
    "        \"区分度\",\n",
    "        \"响应稳定性\",\n",
    "        \"恢复程度\",\n",
    "        \"基线偏差\",\n",
    "        \"大浓度区分度\",\n",
    "        ]\n",
    "        sc=[\"3-30K\",\"2-15\",\"1.1-1.5\",\"0.95~1.05\",\"大于0.75\",\"-0.2~0.1\",\"大于1.3\"]\n",
    "    if data_total.columns.__len__()==9:\n",
    "        mlst =[\"响应电阻\",\n",
    "        \"响应大小\",\n",
    "        \"区分度\",\n",
    "        \"响应稳定性\",\n",
    "        \"恢复程度\",\n",
    "        \"基线偏差\",\n",
    "        ]\n",
    "        sc=[\"3-30K\",\"2-15\",\"1.1-1.5\",\"0.95~1.05\",\"大于0.75\",\"-0.2~0.1\"]\n",
    "    for i,_row in enumerate(mlst):\n",
    "        row_cells = table.add_row().cells \n",
    "        row_cells[0].text = _row\n",
    "        row_cells[1].text = ' '+sc[i]\n",
    "        p = row_cells[1].paragraphs[0]\n",
    "        p.paragraph_format.alignment =WD_ALIGN_PARAGRAPH.JUSTIFY \n",
    "\n",
    "    paragraph = document.add_paragraph(' ')\n",
    "\n",
    "    paragraph = document.add_paragraph('其中符合6参数器件'+str(step_6.__len__())+\"个器件\"+\"，良品率(占测试总数量)为\"+str(round(step_6.__len__()/data_total.__len__(),4)*100)+\"%\")\n",
    "    paragraph = document.add_paragraph('其中符合全部参数且响应浓度值在45~55的器件为：'+str(con_filter_1.__len__())+\"个器件\"+\"，占总数比为\"+str(round(con_filter_1.__len__()/data_total.__len__(),4)*100)+\"%\")\n",
    "    paragraph = document.add_paragraph('其中符合全部参数且响应浓度值在40~45或55~60的器件为：'+str(con_filter_2.__len__())+\"个器件\"+\"，占总数比为\"+str(round(con_filter_2.__len__()/data_total.__len__(),4)*100)+\"%\")\n",
    "\n",
    "    paragraph = document.add_paragraph('其中符合6参数器件:'+str(list(step_6[\"序号\"])))\n",
    "\n",
    "\n",
    "\n",
    "    if data_total.columns.__len__()==10:\n",
    "        paragraph = document.add_paragraph('其中符合7参数器件'+str(step_7.__len__())+\"个器件\"+\"，良品率(占测试总数量)为\"+str(round(step_7.__len__()/data_total.__len__(),4)*100)+\"%\")\n",
    "        paragraph = document.add_paragraph('其中符合7参数器件:'+str(list(step_7[\"序号\"])))\n",
    "\n",
    "\n",
    "\n",
    "    document.add_picture('响应电阻.png', width=Cm(15))\n",
    "    document.add_picture('响应大小.png', width=Cm(15))\n",
    "    document.add_picture('响应稳定性.png', width=Cm(15))\n",
    "    document.add_picture('区分度.png', width=Cm(15))\n",
    "    document.add_picture('恢复程度.png', width=Cm(15))\n",
    "    document.add_picture('基线偏差.png', width=Cm(15))\n",
    "    document.add_picture('响应浓度值.png', width=Cm(15))\n",
    "\n",
    "    if data_total.columns.__len__()==10:\n",
    "        document.add_picture('大浓度区分度值.png', width=Cm(15))\n",
    "\n",
    "    document.add_picture('不良率.png', width=Cm(15))\n",
    "\n",
    "    document.save('report/分析报告_'+batch_name+'.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data_one(filename):\n",
    "    data = pd.read_csv(\"data/\"+filename,sep=r'\\s+',names=[str(i) for i in range(2500)])\n",
    "    num = int(re.findall(r'\\d+', filename[20:-4])[3])\n",
    "    data=data.transpose()\n",
    "    concentration_origin=data.iloc[1024+65:1024+65+num,:]\n",
    "    data=data[65:65+num]\n",
    "    data=data.dropna(how=\"all\",axis=0)\n",
    "    batch_name=filename[15:-4]\n",
    "    return batch_name,data,concentration_origin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_one_by_one(batch_name,scale,data,filename,concentration):\n",
    "\n",
    "    if data.columns.__len__()==8:\n",
    "        response_resistance = data[4]\n",
    "        response_size = data[0]/data[4]\n",
    "        discrimination = data[4]/data[3]\n",
    "        response_stability=data[5]/data[4]\n",
    "        restoration=data[6]/data[0]\n",
    "        baseline_deviation=(data[0]-data[7])/data[0]\n",
    "        high_discrimination=data[2]/data[1]\n",
    "    \n",
    "    if data.columns.__len__()==7:\n",
    "        response_resistance = data[2]\n",
    "        response_size = data[0]/data[2]\n",
    "        discrimination = data[2]/data[1]\n",
    "        response_stability = data[3]/data[2]\n",
    "        restoration = data[4]/data[0]\n",
    "        baseline_deviation=(data[0]-data[6])/data[0]\n",
    "\n",
    "    response_resistance_x=list(scale[scale.index==\"response_resistance_x\"].T[\"response_resistance_x\"])\n",
    "    response_size_x=list(scale[scale.index==\"response_size_x\"].T[\"response_size_x\"])\n",
    "    discrimination_x=list(scale[scale.index==\"discrimination_x\"].T[\"discrimination_x\"])\n",
    "    response_stability_x=list(scale[scale.index==\"response_stability_x\"].T[\"response_stability_x\"])\n",
    "    restoration_x=list(scale[scale.index==\"restoration_x\"].T[\"restoration_x\"])\n",
    "    baseline_deviation_x=list(scale[scale.index==\"baseline_deviation_x\"].T[\"baseline_deviation_x\"])\n",
    "    high_discrimination_x=list(scale[scale.index==\"high_discrimination_x\"].T[\"high_discrimination_x\"])\n",
    "\n",
    "    response_resistance_x=[x for x in response_resistance_x if not math.isnan(x)]\n",
    "    response_size_x=[x for x in response_size_x if not math.isnan(x)]\n",
    "    discrimination_x=[x for x in discrimination_x if not math.isnan(x)]\n",
    "    response_stability_x=[x for x in response_stability_x if not math.isnan(x)]\n",
    "    restoration_x=[x for x in restoration_x if not math.isnan(x)]\n",
    "    baseline_deviation_x=[x for x in baseline_deviation_x if not math.isnan(x)]\n",
    "    high_discrimination_x=[x for x in high_discrimination_x if not math.isnan(x)]\n",
    "\n",
    "    y_1=[0]+list(pd.cut(response_resistance,bins=response_resistance_x).value_counts(sort=False,normalize=True)[:11].values)\n",
    "    y_2=[0]+list(pd.cut(response_size,bins=response_size_x).value_counts(sort=False,normalize=True)[:16].values)\n",
    "    y_3=[0]+list(pd.cut(discrimination,bins=discrimination_x).value_counts(sort=False,normalize=True)[5:25].values)\n",
    "    y_4=[0]+list(pd.cut(response_stability,bins=response_stability_x).value_counts(sort=False,normalize=True)[10:30].values)\n",
    "    y_5=[0]+list(pd.cut(restoration,bins=restoration_x).value_counts(sort=False,normalize=True)[17:-1].values)\n",
    "    y_6=[0]+list(pd.cut(baseline_deviation,bins=baseline_deviation_x).value_counts(sort=False,normalize=True)[15:-1].values)\n",
    "\n",
    "    x_1=response_resistance_x[:12]\n",
    "    x_2=response_size_x[:17]\n",
    "    x_3=discrimination_x[5:26]\n",
    "    x_4=response_stability_x[10:31]\n",
    "    x_5=restoration_x[17:-1]\n",
    "    x_6=baseline_deviation_x[15:-1]\n",
    "    if data.columns.__len__()==8:\n",
    "        x_7=high_discrimination_x[5:27]\n",
    "        y_7=[0]+list(pd.cut(high_discrimination,bins=high_discrimination_x).value_counts(sort=False,normalize=True)[5:26].values)\n",
    "\n",
    "    plt.rcParams['font.sans-serif'] = ['Microsoft YaHei'] \n",
    "    plt.rcParams[\"font.size\"] =35\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    plt.title(\"响应电阻(R$^{1}$$_{50}$)\",pad=40)\n",
    "    plt.xlabel(\"响应电阻(KΩ)\",labelpad=20)\n",
    "    plt.ylabel(\"比例\")\n",
    "    plt.ylim(0,0.8)\n",
    "    plt.grid( axis='y', linewidth=0.3)\n",
    "    plt.plot(x_1, y_1 ,marker='D', markersize=12, linewidth=4.5)\n",
    "    plt.savefig('响应电阻.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    print(\"409600:\",pd.cut(response_resistance,bins=response_resistance_x).value_counts(sort=False).values[-1])\n",
    "\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    plt.title(\"响应大小(R$^{1}$$_{0}$/R$^{1}$$_{50}$)\",pad=40)\n",
    "    plt.xlabel(\"响应大小\",labelpad=20)\n",
    "    plt.ylabel(\"比例\")\n",
    "    plt.ylim(0,0.8)\n",
    "    plt.grid( axis='y', linewidth=0.3)\n",
    "    plt.plot(x_2, y_2, marker='D', markersize=12, linewidth=4.5)\n",
    "    plt.savefig('响应大小.png')\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    plt.title(\"区分度(R$^{1}$$_{50}$/R$_{80}$)\",pad=40)\n",
    "    plt.xlabel(\"区分度\",labelpad=20)\n",
    "    plt.ylabel(\"比例\")\n",
    "    plt.grid( axis='y', linewidth=0.3)\n",
    "    plt.ylim(0,0.8)\n",
    "    plt.plot(x_3, y_3, marker='D', markersize=12, linewidth=4.5)\n",
    "    plt.savefig('区分度.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    plt.title(\"响应稳定性(R$^{2}$$_{50}$/R$^{1}$$_{50}$)\",pad=40)\n",
    "    plt.xlabel(\"响应稳定性\",labelpad=20)\n",
    "    plt.ylabel(\"比例\")\n",
    "    plt.grid( axis='y', linewidth=0.3)\n",
    "    plt.ylim(0,0.8)\n",
    "    plt.plot(x_4, y_4, marker='D', markersize=12, linewidth=4.5)\n",
    "    plt.savefig('响应稳定性.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    plt.title(\"恢复程度(R$_{53}$/R$^{1}$$_{0}$)\",pad=40)\n",
    "    plt.xlabel(\"恢复程度\",labelpad=20)\n",
    "    plt.ylabel(\"比例\")\n",
    "    plt.grid( axis='y', linewidth=0.3)\n",
    "    plt.ylim(0,0.8)\n",
    "    plt.plot(x_5, y_5, marker='D', markersize=12, linewidth=4.5)\n",
    "    plt.savefig('恢复程度.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    plt.title(\"基线偏差[(R$^{1}$$_{0}$-R$^{2}$$_{0}$)/R$^{1}$$_{0}$]\",pad=40)\n",
    "    plt.xlabel(\"基线偏差\",labelpad=20)\n",
    "    plt.ylabel(\"比例\")\n",
    "    plt.grid( axis='y', linewidth=0.3)\n",
    "    plt.ylim(0,0.8)\n",
    "    plt.plot(x_6, y_6, marker='D', markersize=12, linewidth=4.5)\n",
    "    plt.savefig('基线偏差.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    if data.columns.__len__()==8:\n",
    "        plt.figure(figsize=(20, 12))\n",
    "        plt.title(\"大浓度区分度值(R$_{200}$/R$_{100}$)\",pad=40)\n",
    "        plt.xlabel(\"大浓度区分度值\",labelpad=20)\n",
    "        plt.ylabel(\"比例\")\n",
    "        plt.grid( axis='y', linewidth=0.3)\n",
    "        plt.plot(x_7, y_7, marker='D', markersize=12, linewidth=4.5)\n",
    "        plt.savefig('大浓度区分度值.png')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "    no_=data.index.values.astype(int)\n",
    "    if data.columns.__len__()==7:\n",
    "        data_processed = pd.concat(\n",
    "            [pd.Series(no_,index=response_resistance.index),\n",
    "            response_resistance,response_size,discrimination,response_stability,restoration,baseline_deviation\n",
    "            ,concentration],axis=1)\n",
    "        columns=[\"序号\",\"响应电阻\",\n",
    "        \"响应大小\",\n",
    "        \"区分度\",\n",
    "        \"响应稳定性\",\n",
    "        \"恢复程度\",\n",
    "        \"基线偏差\",\n",
    "        \"响应浓度值\"\n",
    "        ]\n",
    "    if data.columns.__len__()==8:\n",
    "        data_processed = pd.concat(\n",
    "            [pd.Series(no_,index=response_resistance.index),\n",
    "            response_resistance,response_size,discrimination,response_stability,restoration,baseline_deviation,high_discrimination\n",
    "            ,concentration],axis=1)\n",
    "        columns=[\"序号\",\"响应电阻\",\n",
    "        \"响应大小\",\n",
    "        \"区分度\",\n",
    "        \"响应稳定性\",\n",
    "        \"恢复程度\",\n",
    "        \"基线偏差\",\n",
    "        \"大浓度区分度\",\n",
    "        \"响应浓度值\"\n",
    "        ]\n",
    "    data_processed.columns=columns\n",
    "\n",
    "    step_1=pd.merge(\n",
    "        data_processed[data_processed[\"响应电阻\"]>=3] , data_processed[data_processed[\"响应电阻\"]<=30],how=\"inner\"\n",
    "        )\n",
    "\n",
    "    step_2=pd.merge(\n",
    "        step_1[step_1[\"响应大小\"]>=2] , step_1[step_1[\"响应大小\"]<=15],how=\"inner\"\n",
    "        )\n",
    "\n",
    "    step_3=pd.merge(\n",
    "        step_2[step_2[\"区分度\"]>=1.1] , step_2[step_2[\"区分度\"]<=1.5],how=\"inner\"\n",
    "        )\n",
    "\n",
    "    step_4=pd.merge(\n",
    "        step_3[step_3[\"响应稳定性\"]>=0.95] , step_3[step_3[\"响应稳定性\"]<=1.05],how=\"inner\"\n",
    "        )\n",
    "\n",
    "    step_5=step_4[step_4[\"恢复程度\"]>0.75]\n",
    "\n",
    "    step_6=pd.merge(\n",
    "        step_5[step_5[\"基线偏差\"]>=-0.2] , step_5[step_5[\"基线偏差\"]<=0.1],how=\"inner\"\n",
    "        )\n",
    "    con_filter_1=pd.merge(\n",
    "        step_6[step_6[\"响应浓度值\"]>=45] , step_6[step_6[\"响应浓度值\"]<=55],how=\"inner\"\n",
    "        )\n",
    "\n",
    "    con_filter_2_1=pd.merge(\n",
    "        step_6[step_6[\"响应浓度值\"]>=40] , step_6[step_6[\"响应浓度值\"]<45],how=\"inner\"\n",
    "        )\n",
    "\n",
    "    con_filter_2_2=pd.merge(\n",
    "        step_6[step_6[\"响应浓度值\"]>55] , step_6[step_6[\"响应浓度值\"]<=60],how=\"inner\"\n",
    "        )\n",
    "\n",
    "    con_filter_2=pd.merge(con_filter_2_1,con_filter_2_2)\n",
    "\n",
    "    if data.columns.__len__()==8:\n",
    "        step_7=step_6[step_6[\"大浓度区分度\"]>1.3]\n",
    "        con_filter_1=pd.merge(\n",
    "    step_6[step_6[\"响应浓度值\"]>=45] , step_6[step_6[\"响应浓度值\"]<=55],how=\"inner\"\n",
    "    )\n",
    "\n",
    "    con_filter_2_1=pd.merge(\n",
    "        step_6[step_6[\"响应浓度值\"]>=40] , step_6[step_6[\"响应浓度值\"]<45],how=\"inner\"\n",
    "        )\n",
    "\n",
    "    con_filter_2_2=pd.merge(\n",
    "        step_6[step_6[\"响应浓度值\"]>55] , step_6[step_6[\"响应浓度值\"]<=60],how=\"inner\"\n",
    "        )\n",
    "\n",
    "    con_filter_2=pd.merge(con_filter_2_1,con_filter_2_2)\n",
    "\n",
    "    step_6_=step_6.copy()\n",
    "    step_6_.index=step_6[\"序号\"]\n",
    "    step_6_.index.name=''\n",
    "    merged = pd.concat([data_processed,step_6_])\n",
    "    merged.drop_duplicates(keep=False,inplace=True)\n",
    "\n",
    "    if data.columns.__len__()==8:\n",
    "        step_7_=step_7.copy()\n",
    "        step_7_.index=step_7[\"序号\"]\n",
    "        step_7_.index.name=''\n",
    "        merged = pd.concat([data_processed,step_7_])\n",
    "        merged.drop_duplicates(keep=False,inplace=True)\n",
    "\n",
    "    defective_products_1 = []\n",
    "    defective_products_1.append(pd.concat(\n",
    "        [merged[merged[\"响应电阻\"]<3] , merged[merged[\"响应电阻\"]>30]]\n",
    "        ).__len__()/merged.__len__())\n",
    "    defective_products_1.append(pd.concat(\n",
    "        [merged[merged[\"响应大小\"]<2] , merged[merged[\"响应大小\"]>15]]\n",
    "        ).__len__()/merged.__len__())\n",
    "    defective_products_1.append(pd.concat(\n",
    "        [merged[merged[\"区分度\"]<1.1] , merged[merged[\"区分度\"]>1.5]]\n",
    "        ).__len__()/merged.__len__())\n",
    "    defective_products_1.append(pd.concat(\n",
    "        [merged[merged[\"响应稳定性\"]<0.95] , merged[merged[\"响应稳定性\"]>1.05]]\n",
    "        ).__len__()/merged.__len__())\n",
    "    defective_products_1.append(merged[merged[\"恢复程度\"]<=0.75].__len__()/merged.__len__())\n",
    "    defective_products_1.append(pd.concat(\n",
    "        [merged[merged[\"基线偏差\"]<-0.2] , merged[merged[\"基线偏差\"]>0.1]]\n",
    "        ).__len__()/merged.__len__())\n",
    "    if data.columns.__len__()==8:\n",
    "        defective_products_1.append(merged[merged[\"大浓度区分度\"]<=1.3].__len__()/merged.__len__())\n",
    "\n",
    "    defective_products_2 = []\n",
    "    defective_products_2.append(pd.concat(\n",
    "        [merged[merged[\"响应电阻\"]<3] , merged[merged[\"响应电阻\"]>30]]\n",
    "        ).__len__())\n",
    "    defective_products_2.append(pd.concat(\n",
    "        [merged[merged[\"响应大小\"]<2] , merged[merged[\"响应大小\"]>15]]\n",
    "        ).__len__())\n",
    "    defective_products_2.append(pd.concat(\n",
    "        [merged[merged[\"区分度\"]<1.1] , merged[merged[\"区分度\"]>1.5]]\n",
    "        ).__len__())\n",
    "    defective_products_2.append(pd.concat(\n",
    "        [merged[merged[\"响应稳定性\"]<0.95] , merged[merged[\"响应稳定性\"]>1.05]]\n",
    "        ).__len__())\n",
    "    defective_products_2.append(merged[merged[\"恢复程度\"]<=0.75].__len__())\n",
    "    defective_products_2.append(pd.concat(\n",
    "        [merged[merged[\"基线偏差\"]<-0.2] , merged[merged[\"基线偏差\"]>0.1]]\n",
    "        ).__len__())\n",
    "    if data.columns.__len__()==8:\n",
    "        defective_products_2.append(merged[merged[\"大浓度区分度\"]<=1.3].__len__())\n",
    "\n",
    "    defective_products_x=[\"不符合响应电阻\",\"不符合响应大小\",\"不符合区分度\",\"不符合响应稳定性\",\"不符合恢复程度\",\"不符基线偏差\"]\n",
    "    if data.columns.__len__()==8:\n",
    "        defective_products_x=[\"不符合响应电阻\",\"不符合响应大小\",\"不符合区分度\",\"不符合响应稳定性\",\"不符合恢复程度\",\"不符基线偏差\",\"不符合大浓度区分度\"]\n",
    "\n",
    "\n",
    "    # sns.set()\n",
    "    plt.rcParams[\"font.size\"] =27\n",
    "    plt.rcParams['font.sans-serif'] = ['Microsoft YaHei'] \n",
    "    # plt.rcParams['font.sans-serif'] = ['SimSun']\n",
    "    fig=plt.figure(figsize=(22, 12),dpi=120)\n",
    "    axis_1 = fig.add_axes((0.1, 0.1, 0.8, 0.8))\n",
    "    # plt.yticks([i for i in np.linspace(0,1,num=6)],[str(round(i,1)*100)[:3]+\"%\"for i in np.linspace(0, 1, num=6)])\n",
    "\n",
    "\n",
    "    colors = [\"#5470C6\" for i in range(defective_products_x.__len__())]\n",
    "    colors[:3]=[\"#A60000\" for i in range(3)]\n",
    "    axis_1.bar(defective_products_x,defective_products_2,width=0.5, alpha=0.8,color=colors,label=\"数量\")\n",
    "    axis_1.set_ylabel(\"数量\", size=30) \n",
    "\n",
    "    plt.legend(['数量'],loc='best',framealpha=0.5)\n",
    "    axis_2 = axis_1.twinx()\n",
    "    axis_2.plot(defective_products_x, defective_products_1, color=\"#6AA84F\", marker=\"o\", linewidth=4.5,label=\"比例\")\n",
    "    for i in range(defective_products_1.__len__()):  \n",
    "        plt.text(defective_products_x[i], defective_products_1[i], str(round(Decimal(defective_products_1[i]),4)*100)[:4]+\"%\", ha='center', va= 'bottom',fontweight='bold')\n",
    "    axis_2.set_ylabel(\"比例\", size=30)\n",
    "    axis_2.xaxis.set_tick_params(pad=20) \n",
    "\n",
    "    # plt.ylim(0,896)\n",
    "    plt.grid(True, linewidth=0.3)\n",
    "    plt.title(batch_name+\"不良品统计情况\", size=45,pad=40)\n",
    "    plt.legend(['比例'],loc=1,framealpha=0.5,bbox_to_anchor=(1,0.90))\n",
    "    plt.savefig(\"不良率.png\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    filtered_no=[]\n",
    "    step_6 = step_6.sort_values(by=\"序号\")\n",
    "    for i in step_6[\"序号\"]:\n",
    "            if int(i)%64 == 0:\n",
    "                filtered_no.append(str(int(i)//64-1)+\"+\"+str(64))\n",
    "            else:  filtered_no.append(str(int(i)//64)+\"+\"+str(int(i)%64))\n",
    "    step_6[\"序号\"]=filtered_no\n",
    "\n",
    "    filtered_no=[]\n",
    "    con_filter_1 = con_filter_1.sort_values(by=\"序号\")\n",
    "    for i in con_filter_1[\"序号\"]:\n",
    "            if int(i)%64 == 0:\n",
    "                filtered_no.append(str(int(i)//64-1)+\"+\"+str(64))\n",
    "            else:  filtered_no.append(str(int(i)//64)+\"+\"+str(int(i)%64))\n",
    "    con_filter_1[\"序号\"]=filtered_no\n",
    "\n",
    "    filtered_no=[]\n",
    "    con_filter_2 = con_filter_2.sort_values(by=\"序号\")\n",
    "    for i in con_filter_2[\"序号\"]:\n",
    "            if int(i)%64 == 0:\n",
    "                filtered_no.append(str(int(i)//64-1)+\"+\"+str(64))\n",
    "            else:  filtered_no.append(str(int(i)//64)+\"+\"+str(int(i)%64))\n",
    "    con_filter_2[\"序号\"]=filtered_no\n",
    "\n",
    "    if data.columns.__len__()==8:\n",
    "        filtered_no=[]\n",
    "        for i in step_7[\"序号\"]:\n",
    "            if int(i)%64 == 0:\n",
    "                filtered_no.append(str(int(i)//64-1)+\"+\"+str(64))\n",
    "            else:  filtered_no.append(str(int(i)//64)+\"+\"+str(int(i)%64))\n",
    "        step_7[\"序号\"]=filtered_no\n",
    "    step_6.to_excel(\"report/processed_\"+batch_name+\".xlsx\")\n",
    "    if data.columns.__len__()==8:\n",
    "        step_7.to_excel(\"report/processed_\"+batch_name+\".xlsx\")\n",
    "\n",
    "    booth=[]\n",
    "    pd.DataFrame([np.array(con_filter_1[\"序号\"]),booth,np.array(con_filter_2[\"序号\"])]).to_csv(\"report/concentration_filter\"+batch_name+\".csv\",index=False,header=False)\n",
    "\n",
    "    defective_products = []\n",
    "    defective_products.append(pd.merge(\n",
    "        data_processed[data_processed[\"响应电阻\"]>=3] , data_processed[data_processed[\"响应电阻\"]<=30],how=\"inner\"\n",
    "        ).__len__()/data_processed.__len__())\n",
    "    defective_products.append(pd.merge(\n",
    "        data_processed[data_processed[\"响应大小\"]>=2] , data_processed[data_processed[\"响应大小\"]<=15],how=\"inner\"\n",
    "        ).__len__()/data_processed.__len__())\n",
    "    defective_products.append(pd.merge(\n",
    "        data_processed[data_processed[\"区分度\"]>=1.1] , data_processed[data_processed[\"区分度\"]<=1.5],how=\"inner\"\n",
    "        ).__len__()/data_processed.__len__())\n",
    "    defective_products.append(pd.merge(\n",
    "        data_processed[data_processed[\"响应稳定性\"]>=0.95] , data_processed[data_processed[\"响应稳定性\"]<=1.05],how=\"inner\"\n",
    "        ).__len__()/data_processed.__len__())\n",
    "    defective_products.append(data_processed[data_processed[\"恢复程度\"]>0.75].__len__()/data_processed.__len__())\n",
    "    defective_products.append(pd.merge(\n",
    "        data_processed[data_processed[\"基线偏差\"]>=-0.2] , data_processed[data_processed[\"基线偏差\"]<=0.1],how=\"inner\"\n",
    "        ).__len__()/data_processed.__len__())\n",
    "    \n",
    "    document =Document()\n",
    "    document.styles['Normal'].font.name='楷体'\n",
    "    document.styles['Normal']._element.rPr.rFonts.set(qn('w:eastAsia'), '楷体')\n",
    "    run=document.add_heading('',level=0).add_run('分析报告')\n",
    "    run.font.name='微软雅黑'\n",
    "    _title = document.styles['Title']\n",
    "    _title.paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER\n",
    "    paragraph = document.add_paragraph('本次测试日期为'+filename[:5]) \n",
    "    paragraph.paragraph_format.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY\n",
    "    paragraph = document.add_paragraph('本次测试批次为'+batch_name+'，一共测试'+str(batch_name[batch_name.find(\"E\")-3:batch_name.find(\"E\")])+\"个器件\")\n",
    "\n",
    "    paragraph = document.add_paragraph('各参数筛选合格率') \n",
    "    paragraph.paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER \n",
    "    table = document.add_table(rows=1, cols=3, style='Table Grid') \n",
    "    table.style.paragraph_format.alignment=WD_ALIGN_PARAGRAPH.CENTER\n",
    "    hdr_cells = table.rows[0].cells\n",
    "    hdr_cells[0].text = '指标名称'\n",
    "    hdr_cells[1].text = '符合参数占比'\n",
    "    hdr_cells[2].text = '不符合参数占比'\n",
    "    table.cell(0,0).width=Cm(5) \n",
    "    table.cell(0,1).width=Cm(10) \n",
    "\n",
    "    if data.columns.__len__()==8:\n",
    "        mlst =[\"序号\",\"响应电阻\",\n",
    "        \"响应大小\",\n",
    "        \"区分度\",\n",
    "        \"响应稳定性\",\n",
    "        \"恢复程度\",\n",
    "        \"基线偏差\",\n",
    "        \"大浓度区分度\",\n",
    "        ]\n",
    "    if data.columns.__len__()==7:\n",
    "        mlst =[\"响应电阻\",\n",
    "        \"响应大小\",\n",
    "        \"区分度\",\n",
    "        \"响应稳定性\",\n",
    "        \"恢复程度\",\n",
    "        \"基线偏差\",\n",
    "        ]\n",
    "    for i,_row in enumerate(mlst):\n",
    "        row_cells = table.add_row().cells # 添一行表格元素\n",
    "        row_cells[0].text = _row\n",
    "        row_cells[1].text = ' '+str(round(defective_products[i],2)*100)+\"%\"\n",
    "        row_cells[2].text = ' '+str(round(Decimal(1-defective_products[i]),2)*100)[:5]+\"%\"\n",
    "        p = row_cells[1].paragraphs[0]\n",
    "        p.paragraph_format.alignment =WD_ALIGN_PARAGRAPH.JUSTIFY # 单元格文字两端对齐\n",
    "\n",
    "    paragraph = document.add_paragraph(' ')\n",
    "\n",
    "    paragraph = document.add_paragraph('参数筛选区间表') \n",
    "    paragraph.paragraph_format.alignment = WD_ALIGN_PARAGRAPH.CENTER \n",
    "    table = document.add_table(rows=1, cols=2, style='Table Grid') \n",
    "    table.style.paragraph_format.alignment=WD_ALIGN_PARAGRAPH.CENTER\n",
    "    hdr_cells = table.rows[0].cells\n",
    "    hdr_cells[0].text = '指标名称'\n",
    "    hdr_cells[1].text = '区间范围'\n",
    "    table.cell(0,0).width=Cm(5) \n",
    "    table.cell(0,1).width=Cm(10) \n",
    "\n",
    "    if data.columns.__len__()==8:\n",
    "        mlst =[\"序号\",\"响应电阻\",\n",
    "        \"响应大小\",\n",
    "        \"区分度\",\n",
    "        \"响应稳定性\",\n",
    "        \"恢复程度\",\n",
    "        \"基线偏差\",\n",
    "        \"大浓度区分度\",\n",
    "        ]\n",
    "        sc=[\"3-30\",\"2-15\",\"1.1-1.5\",\"0.95~1.05\",\"大于0.75\",\"-0.2~0.1\",\"大于1.3\"]\n",
    "    if data.columns.__len__()==7:\n",
    "        mlst =[\"响应电阻\",\n",
    "        \"响应大小\",\n",
    "        \"区分度\",\n",
    "        \"响应稳定性\",\n",
    "        \"恢复程度\",\n",
    "        \"基线偏差\",\n",
    "        ]\n",
    "        sc=[\"3-30\",\"2-15\",\"1.1-1.5\",\"0.95~1.05\",\"大于0.75\",\"-0.2~0.1\"]\n",
    "    for i,_row in enumerate(mlst):\n",
    "        row_cells = table.add_row().cells \n",
    "        row_cells[0].text = _row\n",
    "        row_cells[1].text = ' '+sc[i]\n",
    "        p = row_cells[1].paragraphs[0]\n",
    "        p.paragraph_format.alignment =WD_ALIGN_PARAGRAPH.JUSTIFY \n",
    "\n",
    "    paragraph = document.add_paragraph(' ')\n",
    "\n",
    "    paragraph = document.add_paragraph('其中符合6参数器件'+str(step_6.__len__())+\"个器件\"+\"，良品率(占测试总数量)为\"+str(round(step_6.__len__()/data.__len__(),5)*100)+\"%\")\n",
    "    paragraph = document.add_paragraph('其中符合全部参数且响应浓度值在45~55的器件为：'+str(con_filter_1.__len__())+\"个器件\"+\"，占总数比为\"+str(round(con_filter_1.__len__()/data.__len__(),4)*100)+\"%\")\n",
    "    paragraph = document.add_paragraph('其中符合全部参数且响应浓度值在40~45或55~60的器件为：'+str(con_filter_2.__len__())+\"个器件\"+\"，占总数比为\"+str(round(con_filter_2.__len__()/data.__len__(),4)*100)+\"%\")\n",
    "    paragraph = document.add_paragraph('其中符合6参数器件:'+str(list(step_6[\"序号\"])))\n",
    "\n",
    "    if data.columns.__len__()==8:\n",
    "        paragraph = document.add_paragraph('其中符合7参数器件'+str(step_7.__len__())+\"个器件\"+\"，良品率(占测试总数量)为\"+str(round(step_7.__len__()/data.__len__(),5)*100)+\"%\")\n",
    "        paragraph = document.add_paragraph('其中符合7参数器件:'+str(list(step_7[\"序号\"])))\n",
    "    document.add_picture('响应电阻.png', width=Cm(15))\n",
    "    document.add_picture('响应大小.png', width=Cm(15))\n",
    "    document.add_picture('区分度.png', width=Cm(15))\n",
    "    document.add_picture('恢复程度.png', width=Cm(15))\n",
    "    document.add_picture('基线偏差.png', width=Cm(15))\n",
    "    document.add_picture('响应浓度值.png', width=Cm(15))\n",
    "    document.add_picture('不良率.png', width=Cm(15))\n",
    "\n",
    "\n",
    "    if data.columns.__len__()==8:\n",
    "        document.add_picture('大浓度区分度值.png', width=Cm(15))\n",
    "\n",
    "    document.save('report/分析报告_'+batch_name+'.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concentration_filter_draw(concentration,dindex):\n",
    "    concentration.name=\"concentration\"\n",
    "    concentration.index=dindex\n",
    "    label_1 = np.array([concentration.index[i] for i,x in enumerate(concentration) if (x>=45 and x<=55)])\n",
    "    label_2 = np.array([concentration.index[i] for i,x in enumerate(concentration) if (x>=40 and x<45) or (x>55 and x<=60)])\n",
    "\n",
    "    concentration_x=np.linspace(0,100,num=21)\n",
    "    concentration_count=[0]+list(pd.cut(concentration,bins=concentration_x).value_counts(sort=False,normalize=True).values)\n",
    "\n",
    "    plt.rcParams['font.sans-serif'] = ['Microsoft YaHei'] \n",
    "    plt.rcParams[\"font.size\"] =35\n",
    "    plt.figure(figsize=(20, 12))\n",
    "    plt.title(\"响应浓度值\",pad=40)\n",
    "    plt.xlabel(\"响应浓度值\",labelpad=20)\n",
    "    plt.ylabel(\"比例\")\n",
    "    plt.ylim(0,0.8)\n",
    "    plt.grid( axis='y', linewidth=0.5)\n",
    "    plt.plot(concentration_x, concentration_count, marker='D', markersize=12,linewidth=4.5)\n",
    "    plt.savefig('响应浓度值.png')\n",
    "    plt.close()\n",
    "\n",
    "    return label_1,label_2,concentration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_13016\\3291915462.py:53: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  data_total= pd.concat([data_total,data])\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_13016\\3291915462.py:54: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  concentration_origin_total=pd.concat([concentration_origin_total,concentration_origin])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "409600: 38\n",
      "409600: 38\n"
     ]
    }
   ],
   "source": [
    "filepaths = get_filepaths(\"data\")\n",
    "for i,j in enumerate(filepaths):\n",
    "    filepaths[i]=j[5:]\n",
    "batch,batch_name,batch_name_2,total_num=gain_batch_name(filepaths)\n",
    "scale = import_scale()\n",
    "data_total,concentration_total =concat_data(filepaths)\n",
    "label_1,label_2,concentration=concentration_filter_draw(concentration_total,data_total.index.values)\n",
    "process(batch_name,scale,data_total,total_num,filepaths,concentration)\n",
    "\n",
    "for filename in filepaths:\n",
    "    batch_name,data,concentration=import_data_one(filename)\n",
    "    clabel_1,label_2,concentration=concentration_filter_draw(concentration_total,data.index.values)\n",
    "    process_one_by_one(batch_name,scale,data,filename,concentration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TVOC15BP2B3+878ETH'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>no</th>\n",
       "      <th>batch</th>\n",
       "      <th>concentration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>53.52320</td>\n",
       "      <td>7.08497</td>\n",
       "      <td>9.54801</td>\n",
       "      <td>9.46018</td>\n",
       "      <td>48.19100</td>\n",
       "      <td>15.08850</td>\n",
       "      <td>55.3280</td>\n",
       "      <td>65.0</td>\n",
       "      <td>TVOC15BP2B3+878ETH</td>\n",
       "      <td>44.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>29.70230</td>\n",
       "      <td>8.27386</td>\n",
       "      <td>9.87124</td>\n",
       "      <td>9.84178</td>\n",
       "      <td>26.92900</td>\n",
       "      <td>12.74430</td>\n",
       "      <td>30.9463</td>\n",
       "      <td>66.0</td>\n",
       "      <td>TVOC15BP2B3+878ETH</td>\n",
       "      <td>41.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>47.49730</td>\n",
       "      <td>10.01880</td>\n",
       "      <td>12.03500</td>\n",
       "      <td>12.03500</td>\n",
       "      <td>44.53070</td>\n",
       "      <td>15.70620</td>\n",
       "      <td>50.2568</td>\n",
       "      <td>67.0</td>\n",
       "      <td>TVOC15BP2B3+878ETH</td>\n",
       "      <td>44.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>65.02820</td>\n",
       "      <td>12.40400</td>\n",
       "      <td>15.21800</td>\n",
       "      <td>15.15320</td>\n",
       "      <td>57.84200</td>\n",
       "      <td>20.47060</td>\n",
       "      <td>68.4903</td>\n",
       "      <td>68.0</td>\n",
       "      <td>TVOC15BP2B3+878ETH</td>\n",
       "      <td>44.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>63.12230</td>\n",
       "      <td>13.27430</td>\n",
       "      <td>16.52920</td>\n",
       "      <td>16.46290</td>\n",
       "      <td>52.95000</td>\n",
       "      <td>22.15930</td>\n",
       "      <td>66.3013</td>\n",
       "      <td>69.0</td>\n",
       "      <td>TVOC15BP2B3+878ETH</td>\n",
       "      <td>40.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>38.19160</td>\n",
       "      <td>11.57720</td>\n",
       "      <td>13.65150</td>\n",
       "      <td>13.62000</td>\n",
       "      <td>34.91440</td>\n",
       "      <td>17.19600</td>\n",
       "      <td>39.4620</td>\n",
       "      <td>938.0</td>\n",
       "      <td>TVOC15BP2B3+878ETH</td>\n",
       "      <td>42.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>75.26740</td>\n",
       "      <td>19.55630</td>\n",
       "      <td>23.15090</td>\n",
       "      <td>22.92920</td>\n",
       "      <td>65.96430</td>\n",
       "      <td>91.85010</td>\n",
       "      <td>138.8340</td>\n",
       "      <td>939.0</td>\n",
       "      <td>TVOC15BP2B3+878ETH</td>\n",
       "      <td>100.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>81.23890</td>\n",
       "      <td>15.15320</td>\n",
       "      <td>19.06980</td>\n",
       "      <td>18.89700</td>\n",
       "      <td>70.09970</td>\n",
       "      <td>26.34180</td>\n",
       "      <td>84.3384</td>\n",
       "      <td>940.0</td>\n",
       "      <td>TVOC15BP2B3+878ETH</td>\n",
       "      <td>43.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>4.81064</td>\n",
       "      <td>4.83747</td>\n",
       "      <td>5.24152</td>\n",
       "      <td>5.26857</td>\n",
       "      <td>5.34979</td>\n",
       "      <td>5.56701</td>\n",
       "      <td>5.9493</td>\n",
       "      <td>941.0</td>\n",
       "      <td>TVOC15BP2B3+878ETH</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>102.97300</td>\n",
       "      <td>22.34170</td>\n",
       "      <td>27.56150</td>\n",
       "      <td>27.32360</td>\n",
       "      <td>90.60030</td>\n",
       "      <td>37.35750</td>\n",
       "      <td>106.9730</td>\n",
       "      <td>942.0</td>\n",
       "      <td>TVOC15BP2B3+878ETH</td>\n",
       "      <td>42.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>878 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "65    53.52320   7.08497   9.54801   9.46018  48.19100  15.08850   55.3280   \n",
       "66    29.70230   8.27386   9.87124   9.84178  26.92900  12.74430   30.9463   \n",
       "67    47.49730  10.01880  12.03500  12.03500  44.53070  15.70620   50.2568   \n",
       "68    65.02820  12.40400  15.21800  15.15320  57.84200  20.47060   68.4903   \n",
       "69    63.12230  13.27430  16.52920  16.46290  52.95000  22.15930   66.3013   \n",
       "..         ...       ...       ...       ...       ...       ...       ...   \n",
       "938   38.19160  11.57720  13.65150  13.62000  34.91440  17.19600   39.4620   \n",
       "939   75.26740  19.55630  23.15090  22.92920  65.96430  91.85010  138.8340   \n",
       "940   81.23890  15.15320  19.06980  18.89700  70.09970  26.34180   84.3384   \n",
       "941    4.81064   4.83747   5.24152   5.26857   5.34979   5.56701    5.9493   \n",
       "942  102.97300  22.34170  27.56150  27.32360  90.60030  37.35750  106.9730   \n",
       "\n",
       "        no               batch  concentration  \n",
       "65    65.0  TVOC15BP2B3+878ETH          44.40  \n",
       "66    66.0  TVOC15BP2B3+878ETH          41.65  \n",
       "67    67.0  TVOC15BP2B3+878ETH          44.20  \n",
       "68    68.0  TVOC15BP2B3+878ETH          44.56  \n",
       "69    69.0  TVOC15BP2B3+878ETH          40.62  \n",
       "..     ...                 ...            ...  \n",
       "938  938.0  TVOC15BP2B3+878ETH          42.27  \n",
       "939  939.0  TVOC15BP2B3+878ETH         100.00  \n",
       "940  940.0  TVOC15BP2B3+878ETH          43.69  \n",
       "941  941.0  TVOC15BP2B3+878ETH           0.00  \n",
       "942  942.0  TVOC15BP2B3+878ETH          42.60  \n",
       "\n",
       "[878 rows x 10 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.concat([data_total,concentration_total],axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
